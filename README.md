# pyspark  

https://github.com/orgs/spark-examples/repositories  

## Spark Notes
Use DataFrame/Dataset over RDD    
Use coalesce() over repartition()   
Use mapPartitions() over map()  
Use Serialized data format’s  
Avoid UDF’s (User Defined Functions)  
Caching data in memory  
Reduce expensive Shuffle operations  
Disable DEBUG & INFO Logging  
